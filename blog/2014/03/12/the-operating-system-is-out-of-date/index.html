
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Systems Past: the only 8 software innovations we actually use - Technical Journal</title>
  <meta name="author" content="davidad (David A. Dalrymple)">

  
  <meta name="description" content="Note: This is a position piece, not a technical article. Hat tip to Jake
Skelcy for requesting such a piece. Computers didn&rsquo;t always have &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://davidad.github.io/blog/2014/03/12/the-operating-system-is-out-of-date">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Technical Journal" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Technical Journal</a></h1>
  <h2>Stuff I <a href="http://hackerschool.com/">hack</a></h2>
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:davidad.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div>
<article class="hentry" role="article">
  
  <header>
    
      <h1 class="entry-title">Systems Past: the only 8 software innovations we actually use</h1>
    
    
      <p class="meta">
        








  


<time datetime="2014-03-12T19:21:49-04:00" pubdate data-updated="true">Mar 12<span>th</span>, 2014</time>
        
      </p>
    
  </header>


<div class="entry-content"><p><em>Note: This is a position piece, not a technical article. Hat tip to <a href="https://twitter.com/_JacobJacob">Jake
Skelcy</a> for requesting such a piece.</em></p>

<p>Computers didn&rsquo;t always have operating systems. The earliest machines, like the
<a href="http://en.wikipedia.org/wiki/Harvard_Mark_I">Harvard Mark I</a> and the
<a href="http://en.wikipedia.org/wiki/EDVAC">EDVAC</a>, perfomed one &ldquo;computation&rdquo; at a
time. Whenever a computation finished, with its output printed by a
teletypewriter or recorded on a magnetic tape, the machine would shut down. A
person would then have to notice the machine stopped, unload the output, set up
a new computation by manually loading the input and program instructions, and
finally, press the <strong>start button</strong> to get the machine cranking again. On the
Harvard Mark I, for instance, restarting would involve separately turning on
multiple electric motors and then pressing a button marked MAIN SEQUENCE.</p>

<p><a href="http://commons.wikimedia.org/wiki/File:Harvard_Mark_I_Computer_-_Input-Output_Details.jpg"><img src="http://upload.wikimedia.org/wikipedia/commons/0/07/Harvard_Mark_I_Computer_-_Input-Output_Details.jpg" alt="The control panel of the Harvard Mark
I." /></a></p>

<p><strong>This is the context in which the programming language (PL) and the operating
system (OS) were invented. The year was 1955. Almost everything since then has
been window dressing</strong> (so to speak). In this essay, I&rsquo;m going to tell you my
perspective on the PL and the OS, and the six other things since then which I
consider significant improvements, which have made it into software practice,
and which are neither algorithms nor data structures (but rather system
concepts). Despite those and other incremental changes, to this day<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>, we work
exclusively<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> within software environments which can definitely be considered
programming languages and operating systems, in exactly the same sense as those
phrases were used almost 60 years ago. My position is:</p>

<ul>
<li>Frankly, this is backward, and we ought to admit it.</li>
<li>Most of this stuff was invented by people who had a lot less knowledge and
experience with computing than we have accumulated today. <strong>All</strong> of it was
<strong>invented by people</strong>: mortal, fallible humans like you and me who were
just trying to make something work. With a solid historical perspective we can
dare to do better.</li>
</ul>


<!-- more -->


<p><a name="The-Programming-Language"></a></p>

<h2>1. The Programming Language <a href="#The-Programming-Language">#</a></h2>

<p><strong>Year</strong>: 1955</p>

<h3>Archetype</h3>

<p>Every programming language used today is descended from
<a href="http://en.wikipedia.org/wiki/Fortran#History">FORTRAN</a><sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup>. FORTRAN is an
abbreviation of FORmula TRANslator, and its mission was to translate typewritten
algebraic formulae into executable code.</p>

<h3>Motivation</h3>

<p>Most uses of computers involved numerical calculations, which would be
translated from equation form into machine code by hand (naturally, a
time-consuming process). Multiple people (including <a href="http://en.wikipedia.org/wiki/Grace_Hopper">Grace
Hopper</a>, <a href="http://en.wikipedia.org/wiki/John_Backus">John
Backus</a>, and <a href="http://en.wikipedia.org/wiki/Alick_Glennie">Alick
Glennie</a>) realized that the computer
could be used to automate such translations, and the result was the programming
language.</p>

<h3>Concept</h3>

<p><strong>A programming language is a piece of software that automatically translates a
specially formatted block of linear text into executable code.</strong></p>

<p>It is bizarre that we&rsquo;re still expressing programs entirely with text 59 years
later when the first interactive graphical display appeared <em>4</em> years later<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup>.</p>

<h3>Benefits</h3>

<p>The existence of progamming languages enabled the use of concise notation for
complex ideas, also known as <strong>abstraction</strong>. This not only saves time, but
also makes programs easier to understand and maintain.</p>

<h3>Exemplars</h3>

<ul>
<li><a href="http://en.wikipedia.org/wiki/Lisp_(programming_language)">Lisp</a></li>
<li><a href="http://en.wikipedia.org/wiki/Forth_(programming_language)">Forth</a></li>
<li><a href="http://en.wikipedia.org/wiki/C_(programming_language)">C</a></li>
</ul>


<h3>Drawbacks</h3>

<ul>
<li>FORTRAN&rsquo;s conflation of functions (an algebraic concept) and subroutines (a
programming construct) persists to this day in nearly every piece of
software, and causes no end of problems.
<a href="http://en.wikipedia.org/wiki/Tracing_just-in-time_compilation">Tracing
compilers</a>
scratch the surface of reversing this mistake, but so far I know of no
programming languages that are specifically designed around such a mechanism.</li>
<li>The fact that inputs had to be loaded into computers as stacks of punched
cards limited the possible means of expressing computations &mdash; lines of text.</li>
</ul>


<p><a name="The-Operating-System"></a></p>

<h2>2. The Operating System <a href="#The-Operating-System">#</a></h2>

<p><strong>Year</strong>: 1955</p>

<h3>Archetype</h3>

<p>The <a href="http://www.rand.org/content/dam/rand/pubs/papers/2008/P7316.pdf">General Motors/North American Aviation
Monitor</a> was
arguably the &ldquo;original&rdquo; OS.</p>

<h3>Motivation</h3>

<blockquote><p>The typical mode of operation was programmer present and at the operating
console. When a programmer got ready for a test, he or she signed up on a
first-in, first-out list, much like the list at a crowded restaurant. The
programmer then checked progress frequently to estimate when he would reach
the top. When his time got close, he stood by with card deck in hand. When the
previous person finished or ran out of allotted time or abruptly crashed, the
next programmer rushed in, checked the proper board was installed in the card
reader, checked that the proper board was installed in the printer, checked
that the proper board was installed on the punch, hung a magnetic tape,
punched in on a mechanical time clock, addressed the console, set the
appropriate switches, loaded his punched card deck in the card reader, prayed
the first card would not jam, and pressed the LOAD button to invoke the
bootstrap sequence.</p>

<p>If all went well, you could load a typical deck of about 300 cards and begin
the execution of your first instruction about 5 minutes after entering
the room. If only one person did all this set up and got going in 5 minutes,
he bustled around the machine like a whirling dervish [sic]. Not always did
things go so smoothly. If a programmer was fumble-fingered, cards jammed,
magnetic tapes would not read due to defective splices, printer boards or
switches were incorrectly set up, and it took 10 minutes to get going; or
worse &mdash; you lost your opportunity and the next guy took the machine when your
time ran out. Usually the machine spent more time idle than computing. We
programmers weren&rsquo;t paid very much and although the machine was fairly costly,
its capacity was even a more precious commodity since there were only 17 in
the whole world.</p></blockquote>

<h3>Concept</h3>

<p><strong>An operating system is a piece of software that faciliates the execution of
multiple independent programs on one computer, using standard input and output
routines.</strong></p>

<p>There&rsquo;s a deep connection between the OS concept and the PL concept: the OS
facilitates the execution of independent programs, while the PL facilitates the
execution of independent modules or subroutines. In fact, GM/NAA OS was
<a href="http://millosh.wordpress.com/2007/09/07/the-worlds-first-computer-operating-system-implemented-at-general-motors-research-labs-in-warren-michigan-in-1955/">literally</a>
a modification of the octal code of the FORTRAN compiler tape.</p>

<p>The bizareness about operating systems is that we still accept unquestioningly
that it&rsquo;s a good idea to run multiple programs on a single computer with the
conceit that they&rsquo;re totally independent. Well-specified interfaces are great
<em>semantically</em> for maintainability. But when it comes to what the machine is
<em>actually doing</em>, why not just run one ordinary program and teach it new
functions over time? Why persist for 50 years the fiction that every distinct
function performed by a computer executes independently in its own little barren
environment?</p>

<h3>Benefits</h3>

<ul>
<li>Multiple programs could be run in a &ldquo;batch,&rdquo; thus keeping the machine from
ever being idle (except in case of hardware failure or an empty job queue).</li>
<li>Programmers could now use standard input and output routines. (Depending on
the formatting requirements and particular peripherals in use, properly
handling input and output could previously have consumed most of the
programming effort for simple jobs.)</li>
<li>Bare-hands reconfiguration of hardware (e.g. plugboards) finally disappeared
from the work of programming.</li>
</ul>


<h3>Exemplars</h3>

<ul>
<li><a href="http://en.wikipedia.org/wiki/CP/M">CP/M</a></li>
<li><a href="http://en.wikipedia.org/wiki/ProDOS">ProDOS</a></li>
</ul>


<h3>Drawbacks</h3>

<ul>
<li>Programs expect to use the entire machine, because that&rsquo;s how
programs were run previously and that&rsquo;s what the programmers were used to. The
operating system must therefore isolate programs from each other (in the
simplest/earliest cases, by running each job to completion or termination
before loading the next).</li>
</ul>


<p><a name="Interactivity"></a></p>

<h2>3. Interactivity <a href="#Interactivity">#</a></h2>

<p><strong>Year</strong>: 1958</p>

<h3>Archetype</h3>

<p>The <a href="http://en.wikipedia.org/wiki/TX-0">TX-0</a> machine, one of the first
transistorized computers, was installed at MIT in summer of 1958. The TX-0 had a
monitor (a 512x512 CRT display), a keyboard, and a pointing device (a <a href="http://en.wikipedia.org/wiki/Light_pen">light
pen</a>), making it probably the first
computer with <a href="http://youtu.be/ieuV0A01--c?t=2m41s">a physical interface that we might recognize
today</a>. It also happpens to be the machine
which spawned <a href="http://en.wikipedia.org/wiki/Hackers:_Heroes_of_the_Computer_Revolution#Part_One:_True_Hackers">hacker
culture</a>.</p>

<h3>Motivation</h3>

<p>The TX-0 was a scaled-down (transistorized) offshoot of an Air Force project
called <a href="http://en.wikipedia.org/wiki/Semi-Automatic_Ground_Environment">SAGE</a>,
with the ambitious goal of an electronic, automated, networked missile defense
and early warning radar system.  The development of interactive display
computing had three main causes in this context:</p>

<ul>
<li>it was a natural successor to the analog <a href="http://en.wikipedia.org/wiki/Radar_display">radar display</a></li>
<li>the on-line nature of the task demanded real-time human interaction</li>
<li>the importance of the task meant that funding was no object, so an entire
computer (in fact, the largest and most expensive computer system ever made)
could be &ldquo;wasted&rdquo; on providing such interactivity</li>
</ul>


<p>Because of its transistorized circuitry, the TX-0 needed very little
maintainance or oversight, and for years was left unattended at MIT for pretty
much anybody to use at any time, resulting in a great flourishing of interactive
programs (many of whose names began with the word &ldquo;Expensive,&rdquo; in an
acknowledgment of the absurdity of a $3M machine being available for such
experimentation).</p>

<h3>Concept</h3>

<p><strong>An interactive program is one which consumes input after producing output.</strong>
Prior to SAGE, once a program produced its output, it was done, and the machine
would halt or move on to the next job. What distinguishes an interactive system
is that it will produce some output and then <em>wait</em> until more input is
available.</p>

<h3>Benefits</h3>

<ul>
<li>It became possible to do creative work at a computer.</li>
</ul>


<h3>Exemplars</h3>

<ul>
<li><a href="http://en.wikipedia.org/wiki/Sketchpad">Sketchpad</a></li>
<li><a href="http://en.wikipedia.org/wiki/VisiCalc">VisiCalc</a></li>
<li><a href="http://en.wikipedia.org/wiki/GNU_Emacs">Emacs</a></li>
</ul>


<h3>Drawbacks</h3>

<ul>
<li>&ldquo;Waiting&rdquo; is poorly specified. If a program is waiting for one kind of
input, what if a different kind of input arrives instead? It will fail to
respond until the kind of input it was expecting appears. This problem
continues to crop up in graphics programming, network programming, and other
areas.</li>
</ul>


<p><a name="Transactions"></a></p>

<h2>4. Transactions <a href="#Transactions">#</a></h2>

<p><strong>Year</strong>: 1959</p>

<h3>Archetype</h3>

<p>Before computerization, American Airlines' booking process was labor-intensive
and slow.  IBM realized that the basic idea behind SAGE could be applied to
solve the airline reservation problem, resulting in
<a href="http://en.wikipedia.org/wiki/Sabre_(computer_system)#History">SABRE</a>. The core
of the SABRE operating system later became known as TPF (Transaction Processing
Facility).</p>

<h3>Motivation</h3>

<p>American wanted a system with 1,500 booking terminals across the US and Canada
all linked by modem to a central reservations computer. But what if two
terminals try to book the last seat on a flight at the same moment? A system
like this needs strong guarantees on consistency.</p>

<h3>Concept</h3>

<p><strong>Transactions are operations each guaranteed either to fail without any effect,
or to run in a definite, strict order.</strong> Lots of terminals may attempt to input
transactions, but every terminal must observe the same consistent state of the
system, including a global <a href="http://en.wikipedia.org/wiki/Transaction_log">transaction
log</a> listing each transaction in
the precise order in which it was applied.</p>

<h3>Benefits</h3>

<ul>
<li>This one core idea enabled the development of systems called <strong>databases</strong>,
which can reliably maintain the state of complex data structures across
incessant read and write operations as well as some level of hardware
failures.</li>
<li>Modern <strong>filesystems</strong> are &ldquo;journaled&rdquo;, which means that they implement
transactions.</li>
<li>Transactions are also the key idea behind <strong>version control systems</strong>, which are
increasingly adopted in all corners of the software world. In that context,
they are called &ldquo;commits&rdquo;.</li>
<li>Most recently, the core of crypto-currencies is a crude but clever solution to
a distributed transaction processing problem. (In this context, transactions
are in fact called transactions.)</li>
</ul>


<h3>Exemplars</h3>

<ul>
<li><a href="http://en.wikipedia.org/wiki/Ingres_(database)">Ingres</a></li>
<li><a href="http://en.wikipedia.org/wiki/ZFS">ZFS</a></li>
<li><a href="http://en.wikipedia.org/wiki/Git_(software)">git</a></li>
<li><a href="https://github.com/ethereum/wiki/wiki/%5BEnglish%5D-White-Paper#wiki-basic-building-blocks">ethereum</a></li>
</ul>


<h3>Drawbacks</h3>

<p>None.</p>

<p><a name="Garbage-Collection"></a></p>

<h2>5. Garbage Collection <a href="#Garbage-Collection">#</a></h2>

<p><strong>Year</strong>: 1960</p>

<h3>Archetype</h3>

<p>All garbage-collected environments owe a debt <a href="http://www-formal.stanford.edu/jmc/recursive/node4.html">to
Lisp</a>, the first to
provide such a facility.</p>

<h3>Motivation</h3>

<p>Previously, programs required the manual management of the memory resource; the
programmer had to anticipate when the program would need access to more memory,
and ensure that the program wouldn&rsquo;t consume all the memory on the machine by
not re-using memory locations that hold no-longer-needed data.</p>

<h3>Concept</h3>

<p><strong>A garbage collector (GC) is a piece of software which maintains a data
structure representing available memory, and marks a given memory location as
available whenever it is no longer being referred to.</strong></p>

<h3>Benefits</h3>

<ul>
<li>The programmer doesn&rsquo;t have to think about allocating and deallocating memory
in order to make a working program.</li>
</ul>


<h3>Exemplars</h3>

<ul>
<li><a href="http://en.wikipedia.org/wiki/Genera_(operating_system)">Genera</a></li>
<li><a href="http://wiki.luajit.org/New-Garbage-Collector">LuaJIT</a></li>
</ul>


<h3>Drawbacks</h3>

<ul>
<li>Performance becomes unpredictable due to variable GC pause times.</li>
<li>Memory usage becomes unpredictable due to variable GC effectiveness and
potential reference leaks.</li>
</ul>


<p><a name="Virtualization"></a></p>

<h2>6. Virtualization <a href="#Virtualization">#</a></h2>

<p><strong>Year</strong>: 1961</p>

<h3>Archetype</h3>

<p>The <a href="http://www.computer.org/csdl/proceedings/afips/1961/5059/00/50590279.pdf">Atlas
Supervisor</a>,
developed at the University of Manchester in 1961, has been called &ldquo;the first
recognizable modern operating system&rdquo; and &ldquo;the most significant breakthrough in
the history of operating systems&rdquo;<sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup>.</p>

<h3>Motivation</h3>

<p>System builders wanted the capability to run multiple programs at once, mostly
for the following reason:</p>

<blockquote><p>Whilst one program is halted, awaiting completion of a magnetic tape
transfer for instance, the coordinator routine switches control to the next
program in the object program list which is free to proceed.</p></blockquote>

<p>However, as mentioned earlier, programs were (and still are!) written in such a
way as to assume they have a machine all to themselves. Thus, to bridge the gap,
we need to provide such programs with a &ldquo;virtual&rdquo; environment which they <em>do</em> have
all to themselves.</p>

<h3>Concept</h3>

<p><strong>Virtualization is a general term for software facilities (possibly supported
by hardware acceleration) to run programs as if they each have a computer all
to themselves.</strong> Common forms include:</p>

<ul>
<li><strong>Virtual memory</strong> is a mechanism to translate &ldquo;virtual&rdquo; addresses into fetch
commands against physical data stores, in such a way that each program has a
whole &ldquo;virtual&rdquo; computer to itself, despite sharing physical memory.</li>
<li>A <strong>virtual machine (VM)</strong> is a relatively fast bytecode interpreter which does not
enable programs to directly execute instructions on the physical machine.</li>
<li>In <strong>full virtualization</strong>, a virtual machine exposes the entire host
machine instruction set, thus enabling native programs to run within a VM.</li>
</ul>


<h3>Benefits</h3>

<ul>
<li>Virtual memory makes it possible to only copy data from slow tiers of storage
into fast tiers of storage if and when that &ldquo;page&rdquo; of data is needed.</li>
<li>Virtual memory makes it possible to persist data directly from volatile
storage into nonvolatile storage &ldquo;in the background,&rdquo; without special
handling.</li>
<li>Virtual memory makes it possible for processes to &ldquo;share&rdquo; memory without
out-of-band communication.</li>
<li>VMs have relatively strong security guarantees; because all programs become
paths through an interpreter, one need only show that the interpreter is safe
to confirm that running arbitrary code within the VM is safe.</li>
</ul>


<h3>Exemplars</h3>

<ul>
<li><a href="http://en.wikipedia.org/wiki/Multics">Multics</a></li>
<li><a href="http://www.slideshare.net/jserv/plan-9-not-only-a-better-unix">Plan 9</a>
(unparalleled uniformity between volatile, nonvolatile, and network storage)</li>
<li><a href="http://en.wikipedia.org/wiki/Xen">Xen</a> (full virtualization)</li>
</ul>


<h3>Drawbacks</h3>

<ul>
<li>Virtual memory tries so hard to stay out of the programmer&rsquo;s way that most
programmers don&rsquo;t even have a clear idea of what it is. As a result, its
capabilities tend to be underused.</li>
<li>Virtual memory should have been extended to network resources, but this has
not really happened.</li>
<li>As usually implemented, virtual memory subtly encourages the development of
programs that do not talk to each other, because they are all pretending to
exist in an isolated virtual memory space.</li>
</ul>


<p><a name="Hypermedia"></a></p>

<h2>7. Hypermedia <a href="#Hypermedia">#</a></h2>

<p><strong>Year</strong>: 1968</p>

<h3>Archetype</h3>

<p>Doug Engelbart&rsquo;s <a href="http://en.wikipedia.org/wiki/NLS_(computer_system)">NLS</a>
introduced implementations of:</p>

<ul>
<li>hypertext links</li>
<li>markup language</li>
<li>document version control</li>
<li>videoconferencing</li>
<li>email with hypermedia</li>
<li>hypermedia publishing</li>
<li>flexible windowing modes</li>
</ul>


<h3>Motivation</h3>

<blockquote><p><strong><a href="http://www.dougengelbart.org/pubs/augment-3906.html">Augmenting Human
Intellect</a></strong></p>

<p>By &ldquo;augmenting human intellect&rdquo; we mean increasing the capability of a man to
approach a complex problem situation, to gain comprehension to suit his
particular needs, and to derive solutions to problems. Increased capability in
this respect is taken to mean a mixture of the following: more-rapid
comprehension, better comprehension, the possibility of gaining a useful
degree of comprehension in a situation that previously was too complex,
speedier solutions, better solutions, and the possibility of finding solutions
to problems that before seemed insoluble. And by &ldquo;complex situations&rdquo; we
include the professional problems of diplomats, executives, social scientists,
life scientists, physical scientists, attorneys, designers&mdash;whether the
problem situation exists for twenty minutes or twenty years. We do not speak
of isolated clever tricks that help in particular situations. We refer to a
way of life in an integrated domain where hunches, cut-and-try, intangibles,
and the human &ldquo;feel for a situation&rdquo; usefully co-exist with powerful concepts,
streamlined terminology and notation, sophisticated methods, and high-powered
electronic aids.</p>

<p>Existing, or near-future, technology could certainly provide our professional
problem-solvers with the artifacts they need to have for duplicating and
rearranging text before their eyes, quickly and with a minimum of human
effort. Even so apparently minor an advance could yield total changes in an
individual&rsquo;s repertoire hierarchy that would represent a great increase in
over-all effectivenesa. Normally the necessary equipment would enter the
market slowly; changes from the expected would be small, people would change
their ways of doing things a little at a time, and only gradually would their
accumulated changes create markets for more radical versions of the equipment.
Such an evolutionary process has been typical of the way our repertoire
hierarchies have grown and formed.</p>

<p>But an active research effort, aimed at exploring and evaluating poasible
integrated changes throughout the repertoire hierarchy, could greatly
accelerate this evolutionary process.</p></blockquote>

<h3>Concept</h3>

<p><strong>Hypermedia refers to any communications medium which comprises interactive
systems.</strong> The most popular forms of hypermedia are those employing
<strong>hyperlinks</strong>: certain elements of a viewed object which can be activated
through interaction and whose activation triggers the display of a different
object, which is determined by the hyperlink and possibly also by the
interaction. For example, the World Wide Web is a form of hypermedia
(hypertext), though even HTML5 is not nearly as capable as hypermedia pioneers
like Ted Nelson and Doug Engelbart had probably hoped.</p>

<h3>Benefits</h3>

<ul>
<li>Makes nonlinear communication/expression much easier</li>
<li>A continuum between hypermedia authoring and program authoring eases more
people into being able to craft programs to solve their own problems, which is
good for freedom</li>
<li>Could enable people to organize their own thoughts and lives more elegantly
and smoothly</li>
</ul>


<h3>Exemplars</h3>

<ul>
<li><a href="http://en.wikipedia.org/wiki/HyperCard">HyperCard</a></li>
<li><a href="http://twinery.org/">Twine</a></li>
<li><a href="http://en.wikipedia.org/wiki/Wikipedia">Wikipedia</a></li>
</ul>


<h3>Drawbacks</h3>

<ul>
<li>It&rsquo;s easy to implement bad hypermedia, like HTML.</li>
<li>If a software company makes good enough hypermedia, like
<a href="http://en.wikipedia.org/wiki/HyperCard">HyperCard</a>, it will be quickly
discontinued since it will threaten the rest of the company&rsquo;s product line.</li>
</ul>


<p><a name="Internetworking"></a></p>

<h2>8. Internetworking <a href="#Internetworking">#</a></h2>

<p><strong>Year</strong>: 1969</p>

<h3>Archetype</h3>

<p><a href="http://en.wikipedia.org/wiki/Arpanet">ARPAnet</a> is the quintessential computer
network.  It was originally called &ldquo;the Intergalactic Computer
Network&rdquo; and ultimately became known as simply &ldquo;the Internet&rdquo;.</p>

<h3>Motivation</h3>

<blockquote><p>We had in my office three terminals to three different programs that ARPA was
supporting. One was to the Systems Development Corporation in Santa Monica.
There was another terminal to the Genie Project at U.C. Berkeley. The third
terminal was to the C.T.S.S. project that later became the Multics project at
M.I.T.</p>

<p>The thing that really struck me about this evolution was how these three
systems caused communities to get built. People who didn&rsquo;t know one another
previously would now find themselves using the same system. Because the
systems allowed you to share files, you could find that so-and-so was
interested in such-and-such and he had some data about it. You could contact
him by e-mail and, lo and behold, you would have a whole new relationship.</p>

<p>It wasn&rsquo;t a static medium. It was a dynamic medium. And that gave it a lot of
power.</p>

<p>There was one other trigger that turned me to the ARPAnet. For each of these
three terminals, I had three different sets of user commands. So if I was
talking online with someone at S.D.C. and I wanted to talk to someone I knew
at Berkeley or M.I.T. about this, I had to get up from the S.D.C. terminal, go
over and log into the other terminal and get in touch with them.</p>

<p>I said, oh, man, it&rsquo;s obvious what to do: If you have these three terminals,
there ought to be one terminal that goes anywhere you want to go where you
have interactive computing. That idea is the ARPAnet.</p>

<p>&mdash;<a href="http://en.wikipedia.org/wiki/Robert_Taylor_(computer_scientist)">Bob Taylor</a> (<a href="http://partners.nytimes.com/library/tech/99/12/biztech/articles/122099outlook-bobb.html">source</a>), ARPA IPTO director</p></blockquote>

<h3>Concept</h3>

<p><strong>An internetwork is a set of communications channels between computers, where
each computer is running a service that routes incoming messages to some other
communications channel, so that each message eventually reaches its addressee.</strong>
&ldquo;Messages,&rdquo; in this context, are generally termed &ldquo;packets&rdquo; (and they generally
reach their destination within less than a hundred &ldquo;hops&rdquo;).</p>

<h3>Benefits</h3>

<ul>
<li>Global instant email</li>
<li>Global instant hypertext</li>
<li>Global database-backed applications</li>
<li>Global file sharing</li>
</ul>


<h3>Exemplars</h3>

<ul>
<li><a href="http://en.wikipedia.org/wiki/Internet_protocol">Internet Protocol</a></li>
</ul>


<h3>Drawbacks</h3>

<ul>
<li>Classical internetworking has no built-in
economic component; arrangements between large networks must be negotiated
&ldquo;out of band&rdquo; and encoded in a rather nasty form called
<a href="http://en.wikipedia.org/wiki/Border_Gateway_Protocol">BGP</a>. As a result of
this, individual people or even moderately large corporations usually cannot
internetwork, but must instead purchase access to the Internet. As a result of
<em>this</em>, most communications systems around the world are controlled by unjust oligopolies,
with high barriers to competition and low barriers to various abuses of power.</li>
</ul>


<hr />

<p>So, in conclusion, I find that all the significant concepts in software systems
were invented/discovered in the 15 years between 1955 and 1970. What have we
been doing since then? Mostly making things faster, cheaper, more
memory-consuming, smaller, cheaper, dramatically less efficient, more secure,
and worryingly glitchy. And we&rsquo;ve been rehashing the same ideas over and over
again.  Interactivity is now &ldquo;event-driven programming&rdquo;.  Transactions are now
&ldquo;concurrency&rdquo;. Internetworking is now &ldquo;mesh networking&rdquo;. Also, we have tabbed
browsing now, because overlapping windows were a bad skeuomorphism from the
start, and desktop notifications, because whatever is all the way in the corner
of your screen is probably not very important. &ldquo;Flexible view control&rdquo; is
relegated to the few and the proud who run something like <code>xmonad</code> or
<code>herbstluftwm</code> on their custom-compiled GNU/Linux.</p>

<p>Many good programs have been written. Lots of really important algorithms and
data structures have been invented (though usually not implemented in practice).
Hardware has made <em>so</em> much progress. In the 1960s, a lot of good ideas were
tossed out because they ran too slow, but here in 2014 everything is written in
Python anyway, so let&rsquo;s bring back the good old days, but now with Retina screens
and multi-core gigahertz processors and tens of gigabytes of core memory. Let&rsquo;s
take that 20% performance hit over hand-coded assembler that was unacceptable in
the 1960s, because it&rsquo;s a 10x improvement over what we&rsquo;re doing now.</p>

<p>Most of all, let&rsquo;s rethink the received wisdom that you should teach your
computer to do things in a programming language and run the resulting program on
an operating system. A righteous operating system should be a programming
language. And for goodness' sake, let&rsquo;s not use the entire network stack just to
talk to another process on the same machine which is responsible for managing a
database using the filesystem stack. At least let&rsquo;s use shared memory (that&rsquo;s
what it&rsquo;s <em>for</em>!). But if we believe in the future &mdash; if we believe in ourselves
&mdash; let&rsquo;s dare to ask why, anyway, does the operating system give you this
&ldquo;filesystem&rdquo; thing that&rsquo;s no good as a database and expect you to just accept
that &ldquo;stuff on computers goes in folders, lah&rdquo;? Any decent software environment
ought to have a fully featured database, built in, and no need for a
&ldquo;filesystem&rdquo;.</p>

<p>Reject the notion that one program talking to another should have to invoke
some &ldquo;input/output&rdquo; API. You&rsquo;re the human, and you <em>own</em> this machine.  You get
to say who talks to what when, why, and how if you please. All this software
stuff we&rsquo;re expected to deal with &mdash; files, sockets, function calls &mdash; was just
invented by other mortal people, like you and I, without using any tools we
don&rsquo;t have the equivalent of fifty thousand of. Let&rsquo;s do some old-school hacking
on our new-school hardware &mdash; like the original TX-0 hackers, in assembly,
from the ground up &mdash; and work towards a harmonious world where there is
something new in software systems for the first time since 1969.</p>

<hr />

<p><em>To be continued&hellip;</em></p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Since then, Smalltalk, Forth, and Lisp have all flirted with becoming operating systems, but none achieved economic success, for the simple reason that none of the projects involved attempted to provide value to people. They solved technical problems to validate that their concepts can work in the real world, but did not pursue the delivery of better solutions to real-world problems than would otherwise be possible.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>Serious embedded systems people who write machine code from scratch, this is your time to gloat. You truly deserve the title of engineer. In fact, chances are good that you hold the title &ldquo;electrical engineer&rdquo;. Chances are also good that whatever you engineer isn&rsquo;t computers, so hear me out. On the off-chance that you are an embedded systems person who writes machine code from scratch and you <strong>do</strong> make computers or computer parts, chances are good that you are (a) the bane of some free software driver author&rsquo;s existence, and/or (b) providing an incredibly hard-to-detect hideout for really clever malware. <strong>Please compel your employers to publish technical documentation freely and to use ROMs in place of FLASH so that malware can&rsquo;t take over your lovingly crafted code.</strong> Now, back to our regularly scheduled tirade.<a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p>Yes, there are exceptions, bu they&rsquo;re not the ones you think. The exceptions are those derived from the work of <a href="http://en.wikipedia.org/wiki/Cliff_Shaw">Cliff Shaw</a> (e.g.  <a href="http://en.wikipedia.org/wiki/PLANNER">PLANNER</a>, <a href="http://en.wikipedia.org/wiki/Prolog">Prolog</a>, <a href="http://en.wikipedia.org/wiki/MUMPS">M</a>), those derived from <a href="http://c2.com/cgi/wiki?AplLanguage">APL</a> (e.g.  <a href="http://c2.com/cgi/wiki?JayLanguage">J</a>, <a href="http://c2.com/cgi/wiki?KayLanguage">K</a>, and <a href="https://www.princeton.edu/~hos/mike/transcripts/mcilroy.htm">arguably</a> the UNIX shell/pipeline environment), the <a href="http://www.mt-archive.info/MT-1958-Yngve.pdf">COMIT</a> family (e.g.  <a href="http://c2.com/cgi/wiki?SnobolLanguage">SNOBOL</a>), and the curious corner case of <a href="https://gist.github.com/koo5/4129213">Inform 7</a>. Lisp was inspired by FORTRAN (<a href="http://www-formal.stanford.edu/jmc/history/lisp/node2.html">source</a>). ISWIM (which some programming language histories identify as the &ldquo;root&rdquo; of the ML family) is based on ALGOL 60 (<a href="http://www.cs.cmu.edu/~crary/819-f09/Landin66.pdf">source</a>), which of course is based on FORTRAN. The <a href="http://www.forth.com/resources/evolution/evolve_0.html">Forth</a> family (e.g.  <a href="http://en.wikipedia.org/wiki/PostScript">PostScript</a>, <a href="http://c2.com/cgi/wiki?FactorLanguage">Factor</a>, <a href="http://www.stanford.edu/~ouster/cgi-bin/papers/tcl-usenix.pdf">Tcl</a> via <a href="http://c2.com/cgi/wiki?NetworkExtensibleWindowSystem">NeWS</a>) was rooted in Lisp (<a href="http://www.colorforth.com/HOPL.html">source</a>).  Even COMIT was loosely inspired by FORTRAN (<a href="http://books.google.com/books?id=-GW8lOYl3AAC&amp;lpg=PA53&amp;ots=OzMYwEw0kz&amp;dq=COMIT+FORTRAN&amp;pg=PA53">source</a>).  Machine code could simply be disqualified on the basis that it is not software (the subject of this article), but even all current machine languages feature stack operators, which derive from ALGOL via <a href="http://research.microsoft.com/en-us/um/people/gbell/computer_structures_principles_and_examples/csp0260.htm">Burroughs Large Systems</a>.<a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
<li id="fn:4">
<p>Yes, I&rsquo;m aware of <a href="http://en.wikipedia.org/wiki/Graphical_programming">all this $#!*</a>. If you want to point out that graphical programming languages exist, and they aren&rsquo;t based on FORTRAN, well, they fall outside my definition of &ldquo;programming language&rdquo;, so there. Riddle me this: why does nobody who knows how to program in text ever want to use them? Why do they break down for anything that isn&rsquo;t basically a signal processing task? Why don&rsquo;t they have lambdas, zooming, or style? You know, style. Like Edward Tufte has. Style. Nobody wants to use an ugly visual programming language.<a href="#fnref:4" rev="footnote">&#8617;</a></p></li>
<li id="fn:5">
<p>(<a href="http://books.google.com/books?id=-PDPBvIPYBkC&amp;lpg=PA1&amp;ots=LgbTZ3Z1IO&amp;dq=Classic%20Operating%20Systems%3A%20From%20Batch%20Processing%20to%20Distributed%20Systems&amp;pg=PA7#v=onepage&amp;q=atlas&amp;f=false">source</a>)<a href="#fnref:5" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

</div>


  <footer>
    <p class="meta">
      
  

<span class="byline author vcard">Posted by <span class="fn">davidad (David A. Dalrymple)</span></span>

      








  


<time datetime="2014-03-12T19:21:49-04:00" pubdate data-updated="true">Mar 12<span>th</span>, 2014</time>
      


    </p>
    
      

    
    <p class="meta">
      
        <a class="basic-alignment left" href="/blog/2014/03/10/how-i-think-about-math-relations/" title="Previous Post: How I Think About Math, <br/>Lecture 1: Relations">&laquo; How I Think About Math, <br/>Lecture 1: Relations</a>
      
      
    </p>
  </footer>
</article>

</div>

<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2014/03/12/the-operating-system-is-out-of-date/">Systems Past: the only 8 software innovations we actually use</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/03/10/how-i-think-about-math-relations/">How I Think About Math, <br/>Lecture 1: Relations</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/02/28/python-to-scheme-to-assembly-1/">Python to Scheme to Assembly, <br>Part 1: Recursion and Named Let</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/02/25/overkilling-the-8-queens-problem/">Overkilling the 8-queens problem</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/02/19/relocatable-vs-position-independent-code-or/">Relocatable vs. Position-Independent Code (or, Virtual Memory isn't Just For Swap)</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating...</li>
  </ul>
  
  <a href="https://github.com/davidad">@davidad</a> on GitHub
  
  <script type="text/javascript">
    $(document).ready(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'davidad',
            count: 10,
            skip_forks: false,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>





  
</aside>


    </div>
  </div>
  <footer role="contentinfo"><p>
Copyright &copy; 2014 - <a href="http://davidad.org">davidad</a> (David A. Dalrymple) -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<a class="davidadlink" href="http://davidad.org" target="_blank"><div>a <span>davidad</span> production</div></a>


</body>
</html>
